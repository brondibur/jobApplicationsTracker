{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit"
  },
  "interpreter": {
   "hash": "ccd9d83fb765c20651f14f401201e281cb0cf6e178427e4a781dece7459be6e8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time \n",
    "import json\n",
    "global totalApplications\n",
    "global totalOpenings\n",
    "totalApplications = 0\n",
    "totalOpenings = 0\n",
    "global starttime\n",
    "starttime = time.time()\n",
    "url = \"/display/apptime.html\"\n",
    "jores = webdriver.Chrome('chromedriver')  \n",
    "driver = webdriver.Chrome('chromedriver') \n",
    "driver.minimize_window()\n",
    "jores.get(url)\n",
    "jores.maximize_window()\n",
    "with open(\"details.json\", \"r\") as tfile:\n",
    "    dets = json.load(tfile)\n",
    "if \"Amazon\" in dets:\n",
    "    amazonuid = dets['Amazon'].strip(\"]'[\").split(\"','\")[0]\n",
    "    amazonpwd = dets['Amazon'].strip(\"]'[\").split(\"','\")[1]\n",
    "if \"Linkedin\" in dets:\n",
    "    linkedinuid = dets['Linkedin'].strip(\"]'[\").split(\"','\")[0]\n",
    "    linkedinpwd = dets['Linkedin'].strip(\"]'[\").split(\"','\")[1]\n",
    "if \"Dell\" in dets:\n",
    "    delluid = dets['Dell'].strip(\"]'[\").split(\"','\")[0]\n",
    "    dellpwd = dets['Dell'].strip(\"]'[\").split(\"','\")[1]\n",
    "if \"Adobe\" in dets:\n",
    "    adobeuid = dets['Adobe'].strip(\"]'[\").split(\"','\")[0]\n",
    "    adobepwd = dets['Adobe'].strip(\"]'[\").split(\"','\")[1]\n",
    "if \"Master\" in dets:\n",
    "    masteruid = dets['Master'].strip(\"]'[\").split(\"','\")[0]\n",
    "    masterpwd = dets['Master'].strip(\"]'[\").split(\"','\")[1]\n",
    "if \"Reuters\" in dets:\n",
    "    reuteruid = dets['Reuters'].strip(\"]'[\").split(\"','\")[0]\n",
    "    reuterpwd = dets['Reuters'].strip(\"]'[\").split(\"','\")[1]\n",
    "if \"Boeing\" in dets:\n",
    "    boeinguid = dets['Boeing'].strip(\"]'[\").split(\"','\")[0]\n",
    "    boeingpwd = dets['Boeing'].strip(\"]'[\").split(\"','\")[1]\n",
    "if \"PayPal\" in dets:\n",
    "    paypaluid = dets['PayPal'].strip(\"]'[\").split(\"','\")[0]\n",
    "    paypalpwd = dets['PayPal'].strip(\"]'[\").split(\"','\")[1]\n",
    "if \"Finastra\" in dets:\n",
    "    finastrauid = dets['Finastra'].strip(\"]'[\").split(\"','\")[0]\n",
    "    finastrapwd = dets['Finastra'].strip(\"]'[\").split(\"','\")[1]\n",
    "if \"Honeywell\" in dets:\n",
    "    honeyuid = dets['Honeywell'].strip(\"]'[\").split(\"','\")[0]\n",
    "    honeypwd = dets['Honeywell'].strip(\"]'[\").split(\"','\")[1]\n",
    "if \"Naukri\" in dets:\n",
    "    naukriuid = dets['Naukri'].strip(\"]'[\").split(\"','\")[0]\n",
    "    naukripwd = dets['Naukri'].strip(\"]'[\").split(\"','\")[1]\n",
    "appres = {\"Total\":{'Resume Viewed':0,'Submitted':0,'Application Viewed':0},\"Amazon\":{'Resume Viewed':0,'Submitted':0,'Application Viewed':0},\"Linkedin\":{'Resume Viewed':0,'Submitted':0,'Application Viewed':0},\"Dell\":{'Resume Viewed':0,'Submitted':0,'Application Viewed':0},\"Adobe\":{'Resume Viewed':0,'Submitted':0,'Application Viewed':0},\"Master\":{'Resume Viewed':0,'Submitted':0,'Application Viewed':0},\"Reuters\":{'Resume Viewed':0,'Submitted':0,'Application Viewed':0},\"Boeing\":{'Resume Viewed':0,'Submitted':0,'Application Viewed':0},\"PayPal\":{'Resume Viewed':0,'Submitted':0,'Application Viewed':0},\"Finastra\":{'Resume Viewed':0,'Submitted':0,'Application Viewed':0},\"Honeywell\":{'Resume Viewed':0,'Submitted':0,'Application Viewed':0},\"Naukri\":{'Resume Viewed':0,'Submitted':0,'Application Viewed':0}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Amazon Application Status\n",
    "if 'amazonuid' in locals():\n",
    "    global amazonApplications\n",
    "    global amazonJobIds\n",
    "    global amazonList\n",
    "    amazonApplications = 0\n",
    "    amazonJobIds = []\n",
    "    amazonList = []\n",
    "    url = \"https://account.amazon.jobs/en-US\"\n",
    "    driver.get(url)\n",
    "    print(\"Entering Username\", end='')\n",
    "    for i in range(5):\n",
    "        print(\".\",end='')\n",
    "        time.sleep(1) \n",
    "    print()\n",
    "    sbox = driver.find_element_by_class_name(\"form-control\")\n",
    "    sbox.send_keys(amazonuid)\n",
    "    print(\"Username Entered\")\n",
    "    submit = driver.find_element_by_class_name(\"btn-info\")\n",
    "    submit.click()\n",
    "    print(\"Entering Password\",end='')\n",
    "    for i in range(15):\n",
    "        print(\".\",end='')\n",
    "        time.sleep(1) \n",
    "    print()\n",
    "    pbox = driver.find_element_by_id(\"loginFormPasswordInputField\")\n",
    "    pbox.send_keys(amazonpwd)\n",
    "    print(\"Password Entered\")\n",
    "    submit = driver.find_element_by_class_name(\"btn-main\")\n",
    "    submit.click()\n",
    "    print(\"Logging In\",end='')\n",
    "    for i in range(10):\n",
    "        print(\".\",end='')\n",
    "        time.sleep(1) \n",
    "    print()\n",
    "    print(\"Logged In\")\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    job_profiles = soup.find_all('div', {'class' : 'application card'})\n",
    "    count = 0\n",
    "    print(\"Working on it\",end='')\n",
    "    for job_profile in job_profiles :\n",
    "        amazonList.append({'Serial':count+1,'Title':job_profile.find('div', {'class' : 'job-title'}).text,'Location':job_profile.find('p', {'class' : 'location-text'}).text.split(', ')[-1],'ID':job_profile.find('p', {'class' : 'job-id'}).text.split(': ')[1],'Applied':job_profile.find('p', {'class' : 'application-date'}).text.split(': ')[1],'Status':job_profile.find('p', {'class' : 'application-status-text'}).text.split(job_profile.find('div', {'class' : 'job-title'}).text.split(\" \")[0])[0]})\n",
    "        amazonJobIds.append(job_profile.find('p', {'class' : 'job-id'}).text.split(': ')[1])\n",
    "        count += 1\n",
    "        print('.',end='')\n",
    "        if(count == 10) :\n",
    "            break\n",
    "    totals = int(driver.find_element_by_xpath(\"//div[@class='col-sm-12 job-count-info']\").text.split(\"of \")[1].split(\" \")[0])\n",
    "    nopa = totals//10\n",
    "    while nopa > 0:\n",
    "        submit = driver.find_element_by_xpath(\"//button[@class='btn circle right']\")\n",
    "        submit.click()\n",
    "        time.sleep(2)\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        job_profiles = soup.find_all('div', {'class' : 'application card'})\n",
    "        for job_profile in job_profiles :\n",
    "            amazonList.append({'Serial':count+1,'Title':job_profile.find('div', {'class' : 'job-title'}).text,'Location':job_profile.find('p', {'class' : 'location-text'}).text.split(', ')[-1],'ID':job_profile.find('p', {'class' : 'job-id'}).text.split(': ')[1],'Applied':job_profile.find('p', {'class' : 'application-date'}).text.split(': ')[1],'Status':job_profile.find('p', {'class' : 'application-status-text'}).text.split(job_profile.find('div', {'class' : 'job-title'}).text.split(\" \")[0])[0]})\n",
    "            amazonJobIds.append(job_profile.find('p', {'class' : 'job-id'}).text.split(': ')[1])\n",
    "            count += 1\n",
    "            print('.',end='')\n",
    "            if(count % 10 == 0) :\n",
    "                break\n",
    "        nopa -= 1\n",
    "    amazonApplications = count\n",
    "    totalApplications += amazonApplications\n",
    "    print()\n",
    "    print(\"Amazon Application Status Updated\")\n",
    "    with open(\"applications/amazon.json\", \"w\") as tfile:\n",
    "        tfile.write('{\"Amazon\":[')\n",
    "        for i in range(len(amazonList)):\n",
    "            if(i != len(amazonList) - 1):\n",
    "                tfile.write(re.sub(\"'\",'\"',str(amazonList[i]))+\",\")\n",
    "            else:\n",
    "                tfile.write(re.sub(\"'\",'\"',str(amazonList[i])))\n",
    "            if(re.search('submitted',amazonList[i]['Status'])):\n",
    "                appres['Amazon']['Submitted'] += 1\n",
    "                appres['Total']['Submitted'] += 1\n",
    "            else:\n",
    "                if(amazonList[i]['Status'] in appres['Amazon']):\n",
    "                    appres['Amazon'][amazonList[i]['Status']] += 1\n",
    "                else:\n",
    "                    appres['Amazon'][amazonList[i]['Status']] = 1\n",
    "                if(amazonList[i]['Status'] in appres['Total']):\n",
    "                    appres['Total'][amazonList[i]['Status']] += 1\n",
    "                else:\n",
    "                    appres['Total'][amazonList[i]['Status']] = 1\n",
    "        tfile.write(\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linkedin Application Status\n",
    "if 'linkedinuid' in locals():\n",
    "    global linkedinApplications\n",
    "    global linkedinList\n",
    "    linkedinApplications = 0\n",
    "    linkedinList = []\n",
    "    url = \"https://www.linkedin.com/login\"\n",
    "    urll = \"https://www.linkedin.com/my-items/saved-jobs/\"\n",
    "    driver.get(url)\n",
    "    print(\"Entering Login Credentials\", end='')\n",
    "    for i in range(5):\n",
    "        print(\".\",end='')\n",
    "        time.sleep(1) \n",
    "    print()\n",
    "    sbox = driver.find_element_by_id(\"username\")\n",
    "    pbox = driver.find_element_by_id(\"password\")\n",
    "    sbox.send_keys(linkedinuid)\n",
    "    pbox.send_keys(linkedinpwd)\n",
    "    print(\"Credentials Entered\")\n",
    "    submit = driver.find_element_by_class_name(\"btn__primary--large\")\n",
    "    submit.click()\n",
    "    print(\"Logging In\",end='')\n",
    "    for i in range(10):\n",
    "        print(\".\",end='')\n",
    "        time.sleep(1) \n",
    "    print()\n",
    "    print(\"Logged In\")\n",
    "    driver.get(urll)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    job_profiles = soup.find_all('div', {'class' : 'entity-result__item'})\n",
    "    count = 0\n",
    "    print(\"Working on it\", end='')\n",
    "    for job_profile in job_profiles :\n",
    "        linkedinList.append({'Serial':count+1,'Title':re.sub('\\\\n', '', job_profile.find('span', {'class' : 'entity-result__title-text'}).text),'Company':re.sub('\\\\n', '', job_profile.find('div', {'class' : 'entity-result__primary-subtitle'}).text),'Location':re.sub('\\\\n', '', job_profile.find('div', {'class' : 'entity-result__secondary-subtitle'}).text),'Status':re.sub('\\\\n', '', job_profile.find('span', {'class' : 'entity-result__simple-insight-text'}).text)})\n",
    "        count += 1\n",
    "        print('.',end='')\n",
    "        if(count == 10) :\n",
    "            break\n",
    "    totals = int(driver.find_element_by_xpath(\"//div[@class='flex-0 pl1 t-black t-normal']\").text)\n",
    "    nopa = totals//10\n",
    "    while nopa > 0:\n",
    "        url = \"https://www.linkedin.com/my-items/saved-jobs/?start=\"+str(count)\n",
    "        driver.get(url) \n",
    "        time.sleep(5)\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        job_profiles = soup.find_all('div', {'class' : 'entity-result__item'})\n",
    "        for job_profile in job_profiles :\n",
    "            linkedinList.append({'Serial':count+1,'Title':re.sub('\\\\n', '', job_profile.find('span', {'class' : 'entity-result__title-text'}).text),'Company':re.sub('\\\\n', '', job_profile.find('div', {'class' : 'entity-result__primary-subtitle'}).text),'Location':re.sub('\\\\n', '', job_profile.find('div', {'class' : 'entity-result__secondary-subtitle'}).text),'Status':re.sub('\\\\n', '', job_profile.find('span', {'class' : 'entity-result__simple-insight-text'}).text)})\n",
    "            count += 1\n",
    "            print('.',end='')\n",
    "            if(count == 10) :\n",
    "                break\n",
    "        nopa -= 1\n",
    "    linkedinApplications = count\n",
    "    totalApplications += linkedinApplications\n",
    "    print()\n",
    "    print(\"Linkedin Application Status Updated\")\n",
    "    with open(\"applications/linkedin.json\", \"w\") as tfile:\n",
    "        tfile.write('{\"Linkedin\":[')\n",
    "        for i in range(len(linkedinList)):\n",
    "            if(i != len(linkedinList) - 1):\n",
    "                tfile.write(re.sub(\"'\",'\"',str(linkedinList[i]))+\",\")\n",
    "            else:\n",
    "                tfile.write(re.sub(\"'\",'\"',str(linkedinList[i])))\n",
    "            if(re.search('submitted',linkedinList[i]['Status']) or re.search('Applied',linkedinList[i]['Status'])):\n",
    "                appres['Linkedin']['Submitted'] += 1\n",
    "                appres['Total']['Submitted'] += 1\n",
    "            elif(re.search('Application viewed',linkedinList[i]['Status'])):\n",
    "                appres['Linkedin']['Application Viewed'] += 1\n",
    "                appres['Total']['Application Viewed'] += 1\n",
    "            elif(re.search('Resume',linkedinList[i]['Status'])):\n",
    "                appres['Linkedin']['Resume Viewed'] += 1\n",
    "                appres['Total']['Resume Viewed'] += 1\n",
    "            else:\n",
    "                if(linkedinList[i]['Status'] in appres['Linkedin']):\n",
    "                    appres['Linkedin'][linkedinList[i]['Status']] += 1\n",
    "                else:\n",
    "                    appres['Linkedin'][linkedinList[i]['Status']] = 1\n",
    "                if(linkedinList[i]['Status'] in appres['Total']):\n",
    "                    appres['Total'][linkedinList[i]['Status']] += 1\n",
    "                else:\n",
    "                    appres['Total'][linkedinList[i]['Status']] = 1\n",
    "        tfile.write(\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dell Application Status\n",
    "if 'delluid' in locals():\n",
    "    global dellApplications\n",
    "    global dellList\n",
    "    dellApplications = 0\n",
    "    dellList = []\n",
    "    url = \"https://dell.wd1.myworkdayjobs.com/en-US/External/login\"\n",
    "    driver.get(url)\n",
    "    print(\"Entering Login Credentials\", end='')\n",
    "    for i in range(10):\n",
    "        print(\".\",end='')\n",
    "        time.sleep(1) \n",
    "    print()\n",
    "    sbox = driver.find_element_by_id(\"input-4\")\n",
    "    pbox = driver.find_element_by_id(\"input-5\")\n",
    "    sbox.send_keys(delluid)\n",
    "    pbox.send_keys(dellpwd)\n",
    "    print(\"Credentials Entered\")\n",
    "    submit = driver.find_element_by_class_name(\"css-n6lkdc\")\n",
    "    submit.click()\n",
    "    print(\"Logging In\",end='')\n",
    "    for i in range(10):\n",
    "        print(\".\",end='')\n",
    "        time.sleep(1) \n",
    "    print()\n",
    "    print(\"Logged In\")\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    job_profiles = soup.find_all('tr', {'class' : 'WED1'})\n",
    "    count = 0\n",
    "    print(\"Working on it\", end='')\n",
    "    for job_profile in job_profiles :\n",
    "        dellList.append({'Serial':count+1,'Title':re.sub('\\\\n', '', job_profile.find('div', {'class' : 'gwt-Label WACP WJAP'}).text),'Status':re.sub('\\\\n', '', job_profile.find('div', {'class' : 'wd-Text WGH2 WLH2 WP5'}).text)})\n",
    "        count += 1\n",
    "        print('.',end='')\n",
    "        if(count == 10) :\n",
    "            break\n",
    "    dellApplications = count\n",
    "    totalApplications += dellApplications\n",
    "    print()\n",
    "    print(\"Dell Application Status Updated\")\n",
    "    with open(\"applications/dell.json\", \"w\") as tfile:\n",
    "        tfile.write('{\"Dell\":[')\n",
    "        for i in range(len(dellList)):\n",
    "            if(i != len(dellList) - 1):\n",
    "                tfile.write(re.sub(\"'\",'\"',str(dellList[i]))+\",\")\n",
    "            else:\n",
    "                tfile.write(re.sub(\"'\",'\"',str(dellList[i])))\n",
    "            if(re.search('Submitted',dellList[i]['Status'])):\n",
    "                appres['Dell']['Submitted'] += 1\n",
    "                appres['Total']['Submitted'] += 1\n",
    "            else:\n",
    "                if(dellList[i]['Status'] in appres['Dell']):\n",
    "                    appres['Dell'][dellList[i]['Status']] += 1\n",
    "                else:\n",
    "                    appres['Dell'][dellList[i]['Status']] = 1\n",
    "                if(dellList[i]['Status'] in appres['Total']):\n",
    "                    appres['Total'][dellList[i]['Status']] += 1\n",
    "                else:\n",
    "                    appres['Total'][dellList[i]['Status']] = 1\n",
    "        tfile.write(\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Entering Login Credentials..........\n",
      "Credentials Entered\n",
      "Logging In..........\n",
      "Logged In\n",
      "Working on it..\n",
      "Adobe Application Status Updated\n"
     ]
    }
   ],
   "source": [
    "# Adobe Application Status\n",
    "if 'adobeuid' in locals():\n",
    "    global adobeApplications\n",
    "    global adobeList\n",
    "    adobeApplications = 0\n",
    "    adobeList = []\n",
    "    url = \"https://adobe.wd5.myworkdayjobs.com/en-US/external_experienced/login\"\n",
    "    driver.get(url)\n",
    "    print(\"Entering Login Credentials\", end='')\n",
    "    for i in range(10):\n",
    "        print(\".\",end='')\n",
    "        time.sleep(1) \n",
    "    print()\n",
    "    sbox = driver.find_element_by_id(\"input-4\")\n",
    "    pbox = driver.find_element_by_id(\"input-5\")\n",
    "    sbox.send_keys(adobeuid)\n",
    "    pbox.send_keys(adobepwd)\n",
    "    print(\"Credentials Entered\")\n",
    "    submit = driver.find_element_by_class_name(\"css-vjb50u\")\n",
    "    submit.click()\n",
    "    print(\"Logging In\",end='')\n",
    "    for i in range(10):\n",
    "        print(\".\",end='')\n",
    "        time.sleep(1) \n",
    "    print()\n",
    "    print(\"Logged In\")\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    job_profiles = soup.find_all('tr', {'class' : 'WED1'})\n",
    "    count = 0\n",
    "    print(\"Working on it\", end='')\n",
    "    for job_profile in job_profiles :\n",
    "        adobeList.append({'Serial':count+1,'Title':re.sub('\\\\n', '', job_profile.find('div', {'class' : 'gwt-Label WACP WJAP'}).text),'Status':re.sub('\\\\n', '', job_profile.find('div', {'class' : 'wd-Text WGH2 WLH2 WP5'}).text)})\n",
    "        count += 1\n",
    "        print('.',end='')\n",
    "        if(count == 10) :\n",
    "            break\n",
    "    adobeApplications = count\n",
    "    totalApplications += adobeApplications\n",
    "    print()\n",
    "    print(\"Adobe Application Status Updated\")\n",
    "    with open(\"applications/adobe.json\", \"w\") as tfile:\n",
    "        tfile.write('{\"Adobe\":[')\n",
    "        for i in range(len(adobeList)):\n",
    "            if(i != len(adobeList) - 1):\n",
    "                tfile.write(re.sub(\"'\",'\"',str(adobeList[i]))+\",\")\n",
    "            else:\n",
    "                tfile.write(re.sub(\"'\",'\"',str(adobeList[i])))\n",
    "            if(re.search('In Process',adobeList[i]['Status'])):\n",
    "                appres['Adobe']['Submitted'] += 1\n",
    "                appres['Total']['Submitted'] += 1\n",
    "            else:\n",
    "                if(dellList[i]['Status'] in appres['Adobe']):\n",
    "                    appres['Adobe'][adobeList[i]['Status']] += 1\n",
    "                else:\n",
    "                    appres['Adobe'][adobeList[i]['Status']] = 1\n",
    "                if(adobeList[i]['Status'] in appres['Total']):\n",
    "                    appres['Total'][adobeList[i]['Status']] += 1\n",
    "                else:\n",
    "                    appres['Total'][adobeList[i]['Status']] = 1\n",
    "        tfile.write(\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MasterCard Application Status\n",
    "if 'masteruid' in locals():\n",
    "    global masterApplications\n",
    "    global masterList\n",
    "    masterApplications = 0\n",
    "    masterList = []\n",
    "    url = \"https://mastercard.wd1.myworkdayjobs.com/en-US/CorporateCareers/login\"\n",
    "    driver.get(url)\n",
    "    print(\"Entering Login Credentials\", end='')\n",
    "    for i in range(10):\n",
    "        print(\".\",end='')\n",
    "        time.sleep(1) \n",
    "    print()\n",
    "    sbox = driver.find_element_by_xpath(\"//input[@class='gwt-TextBox WF-M']\")\n",
    "    pbox = driver.find_element_by_xpath(\"//input[@class='gwt-PasswordTextBox WF-M']\")\n",
    "    sbox.send_keys(masteruid)\n",
    "    pbox.send_keys(masterpwd)\n",
    "    print(\"Credentials Entered\")\n",
    "    submit = driver.find_element_by_xpath(\"//div[@class='WI5T WJUO']\")\n",
    "    submit.click()\n",
    "    print(\"Logging In\",end='')\n",
    "    for i in range(10):\n",
    "        print(\".\",end='')\n",
    "        time.sleep(1) \n",
    "    print()\n",
    "    print(\"Logged In\")\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    job_profiles = soup.find_all('tr', {'class' : 'WED1'})\n",
    "    count = 0\n",
    "    print(\"Working on it\", end='')\n",
    "    for job_profile in job_profiles :\n",
    "        masterList.append({'Serial':count+1,'Title':re.sub('\\\\n', '', job_profile.find('div', {'class' : 'gwt-Label WACP WJAP'}).text),'Status':re.sub('\\\\n', '', job_profile.find('div', {'class' : 'wd-Text WGH2 WLH2 WP5'}).text)})\n",
    "        count += 1\n",
    "        print('.',end='')\n",
    "        if(count == 10) :\n",
    "            break\n",
    "    masterApplications = count\n",
    "    totalApplications += masterApplications\n",
    "    print()\n",
    "    print(\"MasterCard Application Status Updated\")\n",
    "    with open(\"applications/master.json\", \"w\") as tfile:\n",
    "        tfile.write('{\"Master\":[')\n",
    "        for i in range(len(masterList)):\n",
    "            if(i != len(masterList) - 1):\n",
    "                tfile.write(re.sub(\"'\",'\"',str(masterList[i]))+\",\")\n",
    "            else:\n",
    "                tfile.write(re.sub(\"'\",'\"',str(masterList[i])))\n",
    "            if(re.search('Received',masterList[i]['Status'])):\n",
    "                appres['Master']['Submitted'] += 1\n",
    "                appres['Total']['Submitted'] += 1\n",
    "            elif(re.search('another candidate',masterList[i]['Status'])):\n",
    "                if('Unsuccessful' in appres['Master']):\n",
    "                    appres['Master']['Unsuccessful'] += 1\n",
    "                else:\n",
    "                    appres['Master']['Unsuccessful'] = 1\n",
    "                if('Unsuccessful' in appres['Total']):\n",
    "                    appres['Total']['Unsuccessful'] += 1\n",
    "                else:\n",
    "                    appres['Total']['Unsuccessful'] = 1\n",
    "                appres['Master']['Unsuccessful'] += 1\n",
    "                appres['Total']['Unsuccessful'] += 1\n",
    "            else:\n",
    "                if(masterList[i]['Status'] in appres['Master']):\n",
    "                    appres['Master'][masterList[i]['Status']] += 1\n",
    "                else:\n",
    "                    appres['Master'][masterList[i]['Status']] = 1\n",
    "                if(masterList[i]['Status'] in appres['Total']):\n",
    "                    appres['Total'][masterList[i]['Status']] += 1\n",
    "                else:\n",
    "                    appres['Total'][masterList[i]['Status']] = 1\n",
    "        tfile.write(\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ThomsonReuters Application Status\n",
    "if 'reuteruid' in locals():\n",
    "    global reuterApplications\n",
    "    global reuterList\n",
    "    reuterApplications = 0\n",
    "    reuterList = []\n",
    "    url = \"https://thomsonreuters.wd5.myworkdayjobs.com/en-US/External_Career_Site/login\"\n",
    "    driver.get(url)\n",
    "    print(\"Entering Login Credentials\", end='')\n",
    "    for i in range(10):\n",
    "        print(\".\",end='')\n",
    "        time.sleep(1) \n",
    "    print()\n",
    "    sbox = driver.find_element_by_id(\"input-4\")\n",
    "    pbox = driver.find_element_by_id(\"input-5\")\n",
    "    sbox.send_keys(reuteruid)\n",
    "    pbox.send_keys(reuterpwd)\n",
    "    print(\"Credentials Entered\")\n",
    "    submit = driver.find_element_by_class_name(\"css-1pskw2x\")\n",
    "    submit.click()\n",
    "    print(\"Logging In\",end='')\n",
    "    for i in range(10):\n",
    "        print(\".\",end='')\n",
    "        time.sleep(1) \n",
    "    print()\n",
    "    print(\"Logged In\")\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    job_profiles = soup.find_all('tr', {'class' : 'WED1'})\n",
    "    count = 0\n",
    "    print(\"Working on it\", end='')\n",
    "    for job_profile in job_profiles :\n",
    "        reuterList.append({'Serial':count+1,'Title':re.sub('\\\\n', '', job_profile.find('div', {'class' : 'gwt-Label WACP WJAP'}).text),'Status':re.sub('\\\\n', '', job_profile.find('div', {'class' : 'wd-Text WGH2 WLH2 WP5'}).text)})\n",
    "        count += 1\n",
    "        print('.',end='')\n",
    "        if(count == 10) :\n",
    "            break\n",
    "    reuterApplications = count\n",
    "    totalApplications += reuterApplications\n",
    "    print()\n",
    "    print(\"ThomsonReuters Application Status Updated\")\n",
    "    with open(\"applications/reuter.json\", \"w\") as tfile:\n",
    "        tfile.write('{\"Reuters\":[')\n",
    "        for i in range(len(reuterList)):\n",
    "            if(i != len(reuterList) - 1):\n",
    "                tfile.write(re.sub(\"'\",'\"',str(reuterList[i]))+\",\")\n",
    "            else:\n",
    "                tfile.write(re.sub(\"'\",'\"',str(reuterList[i])))\n",
    "            if(re.search('In Process',reuterList[i]['Status'])):\n",
    "                appres['Reuters']['Submitted'] += 1\n",
    "                appres['Total']['Submitted'] += 1\n",
    "            else:\n",
    "                if(reuterList[i]['Status'] in appres['Reuters']):\n",
    "                    appres['Reuters'][reuterList[i]['Status']] += 1\n",
    "                else:\n",
    "                    appres['Reuters'][reuterList[i]['Status']] = 1\n",
    "                if(reuterList[i]['Status'] in appres['Total']):\n",
    "                    appres['Total'][reuterList[i]['Status']] += 1\n",
    "                else:\n",
    "                    appres['Total'][reuterList[i]['Status']] = 1\n",
    "        tfile.write(\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GoldmanSachs Application Status\n",
    "\"\"\"\n",
    "global goldApplications\n",
    "global goldList\n",
    "goldApplications = 0\n",
    "goldList = []\n",
    "url = \"https://careers-goldmansachs.icims.com/jobs/login?loginOnly=1\"\n",
    "driver.get(url)\n",
    "emid = \"*****************\"\n",
    "pwd = \"******\"\n",
    "print(\"Entering Login Credentials\", end='')\n",
    "for i in range(10):\n",
    "    print(\".\",end='')\n",
    "    time.sleep(1) \n",
    "print()\n",
    "sbox = driver.find_element_by_xpath(\"//input[@id='login_name_i']\")\n",
    "pbox = driver.find_element_by_xpath(\"//input[@id='login_pass_i']\")\n",
    "sbox.send_keys(emid)\n",
    "pbox.send_keys(pwd)\n",
    "print(\"Credentials Entered\")\n",
    "submit = driver.find_element_by_class_name(\"introp_form_submit_i\")\n",
    "submit.click()\n",
    "print(\"Logging In\",end='')\n",
    "for i in range(10):\n",
    "    print(\".\",end='')\n",
    "    time.sleep(1) \n",
    "print()\n",
    "print(\"Logged In\")\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "job_profiles = soup.find_all('tr', {'class' : 'iCIMS_TableRow'})\n",
    "count = 0\n",
    "print(\"Working on it\", end='')\n",
    "for job_profile in job_profiles :\n",
    "    goldList.append({'Serial':count+1,'Title':re.sub('\\\\n', '', \"-\".join(str(x) for x in job_profile.find('td', {'class' : 'iCIMS_SubmittalTableField_2'}).text.split('Job Title')[1].split('-')[0:-1])),'ID':job_profile.find('td', {'class': 'iCIMS_SubmittalTableField_1'}).text.split('Job ID')[1],'Status':re.sub('\\\\n', '', job_profile.find('td', {'class' : 'iCIMS_SubmittalTableField_3'}).text.split(\"Status\")[1]),\"Updated\":job_profile.find('td', {'class' : 'iCIMS_SubmittalTableField_4'}).text.split(\"Last Update\")[1]})\n",
    "    count += 1\n",
    "    print('.',end='')\n",
    "    if(count == 10) :\n",
    "        break\n",
    "goldApplications = count\n",
    "totalApplications += goldApplications\n",
    "print()\n",
    "print(goldList)\n",
    "print(\"GoldmanSachs Application Status Updated\")\n",
    "driver.close() \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boeing Application Status\n",
    "if 'boeinguid' in locals():\n",
    "    global boeingApplications\n",
    "    global boeingList\n",
    "    boeingApplications = 0\n",
    "    boeingList = []\n",
    "    url = \"https://boeing.wd1.myworkdayjobs.com/en-US/EXTERNAL_CAREERS/login\"\n",
    "    driver.get(url)\n",
    "    print(\"Entering Login Credentials\", end='')\n",
    "    for i in range(10):\n",
    "        print(\".\",end='')\n",
    "        time.sleep(1) \n",
    "    print()\n",
    "    sbox = driver.find_elements_by_xpath(\"//input[@class='gwt-TextBox WF-M']\")[0]\n",
    "    pbox = driver.find_elements_by_xpath(\"//input[@class='gwt-PasswordTextBox WF-M']\")[0]\n",
    "    sbox.send_keys(boeinguid)\n",
    "    pbox.send_keys(boeingpwd)\n",
    "    print(\"Credentials Entered\")\n",
    "    submit = driver.find_element_by_class_name(\"WH5T\")\n",
    "    submit.click()\n",
    "    print(\"Logging In\",end='')\n",
    "    for i in range(10):\n",
    "        print(\".\",end='')\n",
    "        time.sleep(1) \n",
    "    print()\n",
    "    print(\"Logged In\")\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    job_profiles = soup.find_all('tr', {'class' : 'WED1'})\n",
    "    count = 0\n",
    "    print(\"Working on it\", end='')\n",
    "    for job_profile in job_profiles :\n",
    "        boeingList.append({'Serial':count+1,'Title':re.sub('\\\\n', '', job_profile.find('div', {'class' : 'gwt-Label WACP WJAP'}).text),'Status':re.sub('\\\\n', '', job_profile.find('div', {'class' : 'wd-Text WGH2 WLH2 WP5'}).text)})\n",
    "        count += 1\n",
    "        print('.',end='')\n",
    "        if(count == 10) :\n",
    "            break\n",
    "    boeingApplications = count\n",
    "    totalApplications += boeingApplications\n",
    "    print()\n",
    "    print(\"Boeing Application Status Updated\")\n",
    "    with open(\"applications/boeing.json\", \"w\") as tfile:\n",
    "        tfile.write('{\"Boeing\":[')\n",
    "        for i in range(len(boeingList)):\n",
    "            if(i != len(boeingList) - 1):\n",
    "                tfile.write(re.sub(\"'\",'\"',str(boeingList[i]))+\",\")\n",
    "            else:\n",
    "                tfile.write(re.sub(\"'\",'\"',str(boeingList[i])))\n",
    "            if(re.search('Consideration',boeingList[i]['Status'])):\n",
    "                appres['Boeing']['Submitted'] += 1\n",
    "                appres['Total']['Submitted'] += 1\n",
    "            else:\n",
    "                if(boeingList[i]['Status'] in appres['Boeing']):\n",
    "                    appres['Boeing'][boeingList[i]['Status']] += 1\n",
    "                else:\n",
    "                    appres['Boeing'][boeingList[i]['Status']] = 1\n",
    "                if(boeingList[i]['Status'] in appres['Total']):\n",
    "                    appres['Total'][boeingList[i]['Status']] += 1\n",
    "                else:\n",
    "                    appres['Total'][boeingList[i]['Status']] = 1\n",
    "        tfile.write(\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PayPal Application Status\n",
    "if 'paypaluid' in locals():\n",
    "    global paypalApplications\n",
    "    global paypalList\n",
    "    paypalApplications = 0\n",
    "    paypalList = []\n",
    "    url = \"https://wd1.myworkdaysite.com/en-US/recruiting/paypal/jobs/login\"\n",
    "    driver.get(url)\n",
    "    print(\"Entering Login Credentials\", end='')\n",
    "    for i in range(10):\n",
    "        print(\".\",end='')\n",
    "        time.sleep(1) \n",
    "    print()\n",
    "    sbox = driver.find_elements_by_xpath(\"//input[@class='gwt-TextBox WF-M']\")[0]\n",
    "    pbox = driver.find_elements_by_xpath(\"//input[@class='gwt-PasswordTextBox WF-M']\")[0]\n",
    "    sbox.send_keys(paypaluid)\n",
    "    pbox.send_keys(paypalpwd)\n",
    "    print(\"Credentials Entered\")\n",
    "    submit = driver.find_element_by_class_name(\"WH5T\")\n",
    "    submit.click()\n",
    "    print(\"Logging In\",end='')\n",
    "    for i in range(10):\n",
    "        print(\".\",end='')\n",
    "        time.sleep(1) \n",
    "    print()\n",
    "    print(\"Logged In\")\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    job_profiles = soup.find_all('tr', {'class' : 'WED1'})\n",
    "    count = 0\n",
    "    print(\"Working on it\", end='')\n",
    "    for job_profile in job_profiles :\n",
    "        paypalList.append({'Serial':count+1,'Title':re.sub('\\\\n', '', job_profile.find('div', {'class' : 'gwt-Label WACP WJAP'}).text),'Status':re.sub('\\\\n', '', job_profile.find('div', {'class' : 'wd-Text WGH2 WLH2 WP5'}).text)})\n",
    "        count += 1\n",
    "        print('.',end='')\n",
    "        if(count == 10) :\n",
    "            break\n",
    "    paypalApplications = count\n",
    "    totalApplications += paypalApplications\n",
    "    print()\n",
    "    print(\"PayPal Application Status Updated\")\n",
    "    with open(\"applications/paypal.json\", \"w\") as tfile:\n",
    "        tfile.write('{\"PayPal\":[')\n",
    "        for i in range(len(paypalList)):\n",
    "            if(i != len(paypalList) - 1):\n",
    "                tfile.write(re.sub(\"'\",'\"',str(paypalList[i]))+\",\")\n",
    "            else:\n",
    "                tfile.write(re.sub(\"'\",'\"',str(paypalList[i])))\n",
    "            if(re.search('Submitted',paypalList[i]['Status'])):\n",
    "                appres['PayPal']['Submitted'] += 1\n",
    "                appres['Total']['Submitted'] += 1\n",
    "            else:\n",
    "                if(paypalList[i]['Status'] in appres['PayPal']):\n",
    "                    appres['PayPal'][paypalList[i]['Status']] += 1\n",
    "                else:\n",
    "                    appres['PayPal'][paypalList[i]['Status']] = 1\n",
    "                if(paypalList[i]['Status'] in appres['Total']):\n",
    "                    appres['Total'][paypalList[i]['Status']] += 1\n",
    "                else:\n",
    "                    appres['Total'][paypalList[i]['Status']] = 1\n",
    "        tfile.write(\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finastra Application Status\n",
    "if 'finastrauid' in locals():\n",
    "    global finastraApplications\n",
    "    global finastraList\n",
    "    finastraApplications = 0\n",
    "    finastraList = []\n",
    "    url = \"https://dh.wd3.myworkdayjobs.com/DHC/login\"\n",
    "    driver.get(url)\n",
    "    print(\"Entering Login Credentials\", end='')\n",
    "    for i in range(10):\n",
    "        print(\".\",end='')\n",
    "        time.sleep(1) \n",
    "    print()\n",
    "    sbox = driver.find_element_by_id(\"input-4\")\n",
    "    pbox = driver.find_element_by_id(\"input-5\")\n",
    "    sbox.send_keys(finastrauid)\n",
    "    pbox.send_keys(finastrapwd)\n",
    "    print(\"Credentials Entered\")\n",
    "    submit = driver.find_element_by_class_name(\"css-1s1r74k\")\n",
    "    submit.click()\n",
    "    print(\"Logging In\",end='')\n",
    "    for i in range(10):\n",
    "        print(\".\",end='')\n",
    "        time.sleep(1) \n",
    "    print()\n",
    "    print(\"Logged In\")\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    job_profiles = soup.find_all('tr', {'class' : 'WED1'})\n",
    "    count = 0\n",
    "    print(\"Working on it\", end='')\n",
    "    for job_profile in job_profiles :\n",
    "        finastraList.append({'Serial':count+1,'Title':re.sub('\\\\n', '', job_profile.find('div', {'class' : 'gwt-Label WACP WJAP'}).text),'Status':re.sub('\\\\n', '', job_profile.find('div', {'class' : 'wd-Text WGH2 WLH2 WP5'}).text)})\n",
    "        count += 1\n",
    "        print('.',end='')\n",
    "        if(count == 10) :\n",
    "            break\n",
    "    finastraApplications = count\n",
    "    totalApplications += finastraApplications\n",
    "    print()\n",
    "    print(\"Finastra Application Status Updated\")\n",
    "    with open(\"applications/finastra.json\", \"w\") as tfile:\n",
    "        tfile.write('{\"Finastra\":[')\n",
    "        for i in range(len(finastraList)):\n",
    "            if(i != len(finastraList) - 1):\n",
    "                tfile.write(re.sub(\"'\",'\"',str(finastraList[i]))+\",\")\n",
    "            else:\n",
    "                tfile.write(re.sub(\"'\",'\"',str(finastraList[i])))\n",
    "            if(re.search('Submitted',finastraList[i]['Status'])):\n",
    "                appres['Finastra']['Submitted'] += 1\n",
    "                appres['Total']['Submitted'] += 1\n",
    "            else:\n",
    "                if(finastraList[i]['Status'] in appres['Finastra']):\n",
    "                    appres['Finastra'][finastraList[i]['Status']] += 1\n",
    "                else:\n",
    "                    appres['Finastra'][finastraList[i]['Status']] = 1\n",
    "                if(finastraList[i]['Status'] in appres['Total']):\n",
    "                    appres['Total'][finastraList[i]['Status']] += 1\n",
    "                else:\n",
    "                    appres['Total'][finastraList[i]['Status']] = 1\n",
    "        tfile.write(\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naukri Application Status\n",
    "if 'naukriuid' in locals():\n",
    "    global naukriApplications\n",
    "    global naukriList\n",
    "    naukriApplications = 0\n",
    "    naukriList = []\n",
    "    url = \"https://www.naukri.com/myapply/historypage\"\n",
    "    driver.get(url)\n",
    "    print(\"Entering Login Credentials\", end='')\n",
    "    for i in range(5):\n",
    "        print(\".\",end='')\n",
    "        time.sleep(1) \n",
    "    print()\n",
    "    sbox = driver.find_element_by_id(\"usernameField\")\n",
    "    pbox = driver.find_element_by_id(\"passwordField\")\n",
    "    sbox.send_keys(naukriuid)\n",
    "    pbox.send_keys(naukripwd)\n",
    "    print(\"Credentials Entered\")\n",
    "    submit = driver.find_element_by_class_name(\"blue-btn\")\n",
    "    submit.click()\n",
    "    print(\"Logging In\",end='')\n",
    "    for i in range(10):\n",
    "        print(\".\",end='')\n",
    "        time.sleep(1) \n",
    "    print()\n",
    "    print(\"Logged In\")\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    totals = int(driver.find_element_by_class_name(\"grayLTxtBold\").text)\n",
    "    nopa = totals//10\n",
    "    while nopa > 0:\n",
    "        elementer = driver.find_element_by_class_name('jdTuplesContainer')\n",
    "        driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight;\", elementer);\n",
    "        elementer = driver.find_element_by_class_name('appHistWrapper')\n",
    "        driver.execute_script(\"window.scrollTo(0, arguments[0].scrollHeight);\", elementer);\n",
    "        time.sleep(2)\n",
    "        driver.execute_script(\"window.scrollTo(0,0);\");\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        nopa -= 1\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    job_profiles = soup.find_all('div', {'class' : 'jdTupleContainer'})\n",
    "    count = 0\n",
    "    print(\"Working on it\", end='')\n",
    "    for job_profile in job_profiles :\n",
    "        naukriList.append({'Serial':count+1,'Title':re.sub('\\\\n', '', job_profile.find('div', {'class' : 'jdTitle'}).text),'Company':re.sub('\\\\n', '', job_profile.find('span', {'class' : 'company'}).text),'Status':re.sub('\\\\n', '', job_profile.find('span', {'class' : 'title fw500'}).text)})\n",
    "        count += 1\n",
    "        print('.',end='')\n",
    "    naukriApplications = count\n",
    "    totalApplications += naukriApplications\n",
    "    print()\n",
    "    print(\"Naukri Application Status Updated\")\n",
    "    with open(\"applications/naukri.json\", \"w\") as tfile:\n",
    "        tfile.write('{\"Naukri\":[')\n",
    "        for i in range(len(naukriList)):\n",
    "            if(i != len(naukriList) - 1):\n",
    "                tfile.write(re.sub(\"'\",'\"',str(naukriList[i]))+\",\")\n",
    "            else:\n",
    "                tfile.write(re.sub(\"'\",'\"',str(naukriList[i])))\n",
    "            if(re.search('Application Sent',naukriList[i]['Status'])):\n",
    "                appres['Naukri']['Submitted'] += 1\n",
    "                appres['Total']['Submitted'] += 1\n",
    "            else:\n",
    "                z = naukriList[i]['Status'].split(' ')\n",
    "                z = str(z[0]+' '+z[1])\n",
    "                if(z in appres['Naukri']):\n",
    "                    appres['Naukri'][z] += 1\n",
    "                else:\n",
    "                    appres['Naukri'][z] = 1\n",
    "                if(z in appres['Total']):\n",
    "                    appres['Total'][z] += 1\n",
    "                else:\n",
    "                    appres['Total'][z] = 1\n",
    "        tfile.write(\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Honeywell Application Status\n",
    "if 'honeyuid' in locals():\n",
    "    global honeyApplications\n",
    "    global honeyList\n",
    "    honeyApplications = 0\n",
    "    honeyList = []\n",
    "    url = \"https://honeywell.csod.com/ats/careersite/login.aspx\"\n",
    "    urll = 'https://honeywell.csod.com/ATS/careersite/ds.aspx?routename=ATS/CareerSite/MyProfile&c=honeywell&site=1'\n",
    "    driver.get(url)\n",
    "    print(\"Entering Login Credentials\", end='')\n",
    "    for i in range(10):\n",
    "        print(\".\",end='')\n",
    "        time.sleep(1) \n",
    "    print()\n",
    "    sbox = driver.find_element_by_id('ctl00_siteContent_txtEmail')\n",
    "    pbox = driver.find_element_by_id('ctl00_siteContent_txtPassword')\n",
    "    sbox.send_keys(honeyuid)\n",
    "    pbox.send_keys(honeypwd)\n",
    "    print(\"Credentials Entered\")\n",
    "    submit = driver.find_element_by_xpath(\"//a[@class='btn-lnk c-bg-corp']\")\n",
    "    submit.click()\n",
    "    print(\"Logging In\",end='')\n",
    "    for i in range(10):\n",
    "        print(\".\",end='')\n",
    "        time.sleep(1) \n",
    "    driver.get(urll)\n",
    "    for i in range(5):\n",
    "        print(\".\",end='')\n",
    "        time.sleep(1) \n",
    "    print()\n",
    "    print(\"Logged In\")\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    job_profiles = soup.find_all('div', {'class' : 'c-bdr-gr10'})\n",
    "    count = 0\n",
    "    print(\"Working on it\", end='')\n",
    "    for job_profile in job_profiles :\n",
    "        a = job_profile.find('div',{\"class\":\"gt-small\"}).text.split(\": \")\n",
    "        honeyList.append({'Serial':count+1,'Title':re.sub('\\\\n', '', job_profile.find('a', {'class' : 'cso-text-xlarge'}).text),'Status':a[3].split(' ')[0],\"ID\":a[1].split(' ')[0],\"Updated\":a[2].split(' ')[0]})\n",
    "        count += 1\n",
    "        print('.',end='')\n",
    "        if(count == 10) :\n",
    "            break\n",
    "    honeyApplications = count\n",
    "    totalApplications += honeyApplications\n",
    "    print()\n",
    "    print(\"Honeywell Application Status Updated\")\n",
    "    driver.close()\n",
    "    with open(\"applications/honeywell.json\", \"w\") as tfile:\n",
    "        tfile.write('{\"Honeywell\":[')\n",
    "        for i in range(len(honeyList)):\n",
    "            if(i != len(honeyList) - 1):\n",
    "                tfile.write(re.sub(\"'\",'\"',str(honeyList[i]))+\",\")\n",
    "            else:\n",
    "                tfile.write(re.sub(\"'\",'\"',str(honeyList[i])))\n",
    "            if(re.search('Submitted',honeyList[i]['Status'])):\n",
    "                appres['Honeywell']['Submitted'] += 1\n",
    "                appres['Total']['Submitted'] += 1\n",
    "            else:\n",
    "                if(honeyList[i]['Status'] in appres['Finastra']):\n",
    "                    appres['Honeywell'][honeyList[i]['Honeywell']] += 1\n",
    "                else:\n",
    "                    appres['Honeywell'][honeyList[i]['Status']] = 1\n",
    "                if(honeyList[i]['Status'] in appres['Total']):\n",
    "                    appres['Total'][honeyList[i]['Status']] += 1\n",
    "                else:\n",
    "                    appres['Total'][honeyList[i]['Status']] = 1\n",
    "        tfile.write(\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "global jstime\n",
    "global apptime\n",
    "apptime = (time.time() - starttime)//60\n",
    "jstime = time.time()\n",
    "explode = []\n",
    "for i in range(0,len(appres['Total'])):\n",
    "    if((i+1)%2==0):\n",
    "        explode.append(0)\n",
    "    else:\n",
    "        explode.append(0.1)\n",
    "fig, ax1 = plt.subplots(figsize = (16,8))\n",
    "ax1.pie([appres['Total'][i] for i in appres['Total']], labels=[i for i in appres['Total']], autopct = \"%d%%\", shadow = True, startangle=180, explode=explode)\n",
    "ax1.legend([i for i in appres['Total']], loc='upper right')\n",
    "plt.tight_layout() \n",
    "plt.savefig('applications/applications.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "print(apptime)\n",
    "with open(\"applications/total.json\", \"w\") as tfile:\n",
    "    tfile.write(str(appres))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uname = ''\n",
    "if \"Name\" in dets:\n",
    "    uname = dets['Name']\n",
    "newContent = \"\\n\" + 'var name = \"'+ str(uname) + '\"\\n' + \"var totapp = \"+ str(totalApplications) + \"\\n\"  + \"var amazonapp = \"+ str(amazonApplications) + \"\\n\" + \"var linkedinapp = \"+ str(linkedinApplications) + \"\\n\" + \"var dellapp = \"+ str(dellApplications) + \"\\n\" + \"var adobeapp = \"+ str(adobeApplications) + \"\\n\" + \"var masterapp = \"+ str(masterApplications) + \"\\n\" + \"var reuterapp = \"+ str(reuterApplications) + \"\\n\" + \"var boeingapp = \"+ str(boeingApplications) + \"\\n\" + \"var paypalapp = \"+ str(paypalApplications) + \"\\n\" + \"var finastraapp = \"+ str(finastraApplications) + \"\\n\" + \"var honeyapp = \"+ str(honeyApplications) + \"\\n\" + \"var naukritapp = \"+ str(naukriApplications) + \"\\n\" + \"var appdeet = \"+ str(appres) + \"\\n\"\n",
    "\n",
    "with open(\"display/jat.html\") as inf:\n",
    "    txt = inf.read()\n",
    "    soup = BeautifulSoup(txt, \"html.parser\")\n",
    "\n",
    "a = soup.find(\"script\", {\"class\":\"contentInput\"})\n",
    "a.clear()\n",
    "a.append(newContent)\n",
    "with open(\"display/jat.html\", \"w\") as outf:\n",
    "    outf.write(str(soup))\n",
    "url = \"/display/jat.html\"\n",
    "jores.get(url)\n",
    "jores.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Amazon - Software Development Engineer Job Search\n",
    "global amazonOpeningsTotal\n",
    "global amazonOpenings\n",
    "amazonOpeningsTotal = 0\n",
    "amazonOpenings = []\n",
    "url = \"https://www.amazon.jobs/en/search?offset=0&result_limit=10&sort=recent&category%5B%5D=software-development&category%5B%5D=machine-learning-science&category%5B%5D=data-science&job_type%5B%5D=Full-Time&cities%5B%5D=Noida%2C%20Uttar%20Pradesh%2C%20IND&cities%5B%5D=Mumbai%2C%20Maharashtra%2C%20IND&cities%5B%5D=Pune%2C%20Maharashtra%2C%20IND&cities%5B%5D=Gurugram%2C%20Haryana%2C%20IND&cities%5B%5D=Bengaluru%2C%20Karnataka%2C%20IND&category_type=Corporate&distanceType=Mi&radius=24km&latitude=&longitude=&loc_group_id=&loc_query=India&base_query=Software%20Development%20Engineer&city=&country=IND&region=&county=&query_options=&\"\n",
    "  \n",
    "driver = webdriver.Chrome('chromedriver')  \n",
    "driver.minimize_window()\n",
    "driver.get(url) \n",
    "print('Updating Amazon Openings')\n",
    "time.sleep(10)\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "all_divs = soup.find_all('div', {'class' : 'job-tile'})\n",
    "job_profiles = []\n",
    "for divs in all_divs:\n",
    "    job_profiles += divs.find_all('a')\n",
    "\n",
    "totals = int(soup.find('div', {'class' : 'job-count-info'}).text.split(\"of \")[1].split(\" \")[0])\n",
    "count = 0\n",
    "jono = 1\n",
    "print(\"Working on it\", end=' ')\n",
    "print(' ', end='')\n",
    "for job_profile in job_profiles :\n",
    "    a = job_profile.find('h3', {'class' : 'job-title'}).text\n",
    "    if a==\"Software Development Engineer\" or a==\"Software Dev Engineer\" or re.search(\"Software Development Engineer Graduate\",a) or a==\"Software Development Engineer I\" or re.search(\"Software Development Engineer I \",a) or re.search(\"Amazon Tech U Graduate Program\",a) or a==\"SDE-I\" or a==\"SDE\" or re.search(\"Software Development Engineer -\",a) or re.search(\"Software Development Engineer I,\",a):\n",
    "        c = job_profile.find('p', {'class' : 'location-and-id'}).text.split(', ')[2].split(' | ')[1].split(\": \")[1]\n",
    "        if c not in amazonJobIds:\n",
    "            g = a.lower().split(\" \")\n",
    "            h = \"\"\n",
    "            for i in g:\n",
    "                h += i\n",
    "                h+= \"-\"\n",
    "            i = \"https://www.amazon.jobs/en/jobs/\"+c+\"/\"+h\n",
    "            amazonOpenings.append({\"Serial\":jono,\"Title\":a,\"Location\":job_profile.find('p', {'class' : 'location-and-id'}).text.split(', ')[2].split(' | ')[0],\"ID\":c,\"Posted\":job_profile.find('h2', {'class' : 'posting-date'}).text.split('Posted ')[1],\"Description\":job_profile.find('p', {'class' : 'description'}).text.split(\"Read more\")[0],\"Updated\":job_profile.find('p', {'class' : 'time-elapsed'}).text,\"Link\":i})\n",
    "            jono += 1\n",
    "    count = count + 1\n",
    "    print('.',end='')\n",
    "    if(count == 10) :\n",
    "        break\n",
    "\n",
    "nopa = totals//10\n",
    "while nopa > 0:\n",
    "    url = \"https://www.amazon.jobs/en/search?offset=\"+str(count)+\"&result_limit=10&sort=recent&category%5B%5D=software-development&category%5B%5D=machine-learning-science&category%5B%5D=data-science&job_type%5B%5D=Full-Time&cities%5B%5D=Noida%2C%20Uttar%20Pradesh%2C%20IND&cities%5B%5D=Mumbai%2C%20Maharashtra%2C%20IND&cities%5B%5D=Pune%2C%20Maharashtra%2C%20IND&cities%5B%5D=Gurugram%2C%20Haryana%2C%20IND&cities%5B%5D=Bengaluru%2C%20Karnataka%2C%20IND&category_type=Corporate&distanceType=Mi&radius=24km&latitude=&longitude=&loc_group_id=&loc_query=India&base_query=Software%20Development%20Engineer&city=&country=IND&region=&county=&query_options=&\"\n",
    "    driver.get(url) \n",
    "    time.sleep(10) \n",
    "    \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    all_divs = soup.find_all('div', {'class' : 'job-tile'})\n",
    "    job_profiles = []\n",
    "    for divs in all_divs:\n",
    "        job_profiles += divs.find_all('a')\n",
    "\n",
    "    totals = int(soup.find('div', {'class' : 'job-count-info'}).text.split(\"of \")[1].split(\" \")[0])\n",
    "    for job_profile in job_profiles :\n",
    "        a = job_profile.find('h3', {'class' : 'job-title'}).text\n",
    "        if a==\"Software Development Engineer\" or a==\"Software Dev Engineer\" or a==\"SOFTWARE DEVELOPMENT ENGINEER\" or re.search(\"Software Development Engineer Graduate\",a) or a==\"Software Development Engineer I\" or re.search(\"Software Development Engineer I \",a) or re.search(\"Amazon Tech U Graduate Program\",a) or a==\"SDE-I\" or a==\"SDE\" or re.search(\"Software Development Engineer -\",a) or re.search(\"Software Development Engineer I,\",a):\n",
    "            c = job_profile.find('p', {'class' : 'location-and-id'}).text.split(', ')[2].split(' | ')[1].split(\": \")[1]\n",
    "            if c not in amazonJobIds:\n",
    "                g = a.lower().split(\" \")\n",
    "                h = \"\"\n",
    "                for i in g:\n",
    "                    h += i\n",
    "                    h+= \"-\"\n",
    "                i = \"https://www.amazon.jobs/en/jobs/\"+c+\"/\"+h\n",
    "                amazonOpenings.append({\"Serial\":jono,\"Title\":a,\"Location\":job_profile.find('p', {'class' : 'location-and-id'}).text.split(', ')[2].split(' | ')[0],\"ID\":c,\"Posted\":job_profile.find('h2', {'class' : 'posting-date'}).text.split('Posted ')[1],\"Description\":job_profile.find('p', {'class' : 'description'}).text.split(\"Read more\")[0],\"Updated\":job_profile.find('p', {'class' : 'time-elapsed'}).text,\"Link\":i})\n",
    "                jono += 1\n",
    "        count = count + 1\n",
    "        print('.',end='')\n",
    "        if(count == 10) :\n",
    "            break\n",
    "    print(\"%i pages left\"%nopa)\n",
    "    nopa -= 1\n",
    "print()\n",
    "print(\"Amazon Openings Updated\")\n",
    "amazonOpeningsTotal = count\n",
    "totalOpenings += amazonOpeningsTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dell - Software Development Engineer Job Search\n",
    "global dellOpeningsTotal\n",
    "global dellOpenings\n",
    "dellOpeningsTotal = 0\n",
    "dellOpenings = []\n",
    "url = \"https://dell.wd1.myworkdayjobs.com/External/\"\n",
    "driver.get(url) \n",
    "print('Updating Dell Openings', end='')\n",
    "for i in range(10):\n",
    "    print(\".\",end='')\n",
    "    time.sleep(1) \n",
    "print()\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "submit = driver.find_element_by_id('wd-FacetValue-CheckBox-Location_Country::c4f78be1a8f14da0ab49ce1162348a5e-input')\n",
    "driver.execute_script(\"arguments[0].click();\", submit);\n",
    "time.sleep(3) \n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "submit = driver.find_element_by_id('wd-FacetValue-CheckBox-Job_Profiles::914289f44c2f016f83a24faa9c395ce6-input')\n",
    "driver.execute_script(\"arguments[0].click();\", submit);\n",
    "time.sleep(3) \n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "totals = int(soup.find('span', {'class' : 'gwt-InlineLabel WMNO WNNO'}).text.split(\" \")[0])\n",
    "nopa = totals//50\n",
    "while nopa > 0:\n",
    "    elementer = driver.find_element_by_class_name('WAOO WENO')\n",
    "    driver.execute_script(\"window.scrollTo(0, arguments[0].scrollHeight);\", elementer);\n",
    "    time.sleep(2)\n",
    "    driver.execute_script(\"window.scrollTo(0,0);\");\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    nopa -= 1\n",
    "count = 0\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "print(\"Working on it \", end='')\n",
    "job_profiles = soup.find_all('li', {'class' : 'WP4F WBPO WAAB WGAG'})\n",
    "for job_profile in job_profiles :\n",
    "    dellOpenings.append({\"Serial\":count+1,\"Title\":job_profile.find('div', {'class' : 'gwt-Label WACP WJAP'}).text,\"Location\":job_profile.find('span', {'class' : 'gwt-InlineLabel WDAG WC5F'}).text.split(' | ')[1].split(',')[0],\"ID\":job_profile.find('span', {'class' : 'gwt-InlineLabel WDAG WC5F'}).text.split(' | ')[0],\"Posted\":job_profile.find('span', {'class' : 'gwt-InlineLabel WDAG WC5F'}).text.split(' | ')[2].split(\"Posted \")[1]})\n",
    "    count = count + 1\n",
    "    print('.',end='')\n",
    "print()\n",
    "print(\"Dell Openings Updated\")\n",
    "dellOpeningsTotal = count\n",
    "totalOpenings += dellOpeningsTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disney + Hoststar Openings\n",
    "urls = [\"https://jobs.lever.co/hotstar/?location=Bangalore%2FMumbai%2F%20Gurgaon&department=1.%20Engineering&team=Web\",\"https://jobs.lever.co/hotstar/?location=Bangalore%2FMumbai%2F%20Gurgaon&department=1.%20Engineering&team=Ad%20Tech\",\"https://jobs.lever.co/hotstar/?location=Bangalore%2FMumbai%2F%20Gurgaon&department=1.%20Engineering&team=Cloud%20Infrastructure\",\"https://jobs.lever.co/hotstar/?location=Bangalore%2FMumbai%2F%20Gurgaon&department=1.%20Engineering&team=Engineering%20Productivity\",\"https://jobs.lever.co/hotstar/?location=Bangalore%2FMumbai%2F%20Gurgaon&department=1.%20Engineering&team=International%20and%20Growth\",\"https://jobs.lever.co/hotstar/?location=Bangalore%2FMumbai%2F%20Gurgaon&department=1.%20Engineering&team=Living%20Room%20Devices\",\"https://jobs.lever.co/hotstar/?location=Bangalore%2FMumbai%2F%20Gurgaon&department=1.%20Engineering&team=Machine%20Learning\",\"https://jobs.lever.co/hotstar/?location=Bangalore%2FMumbai%2F%20Gurgaon&department=1.%20Engineering&team=Personalization\",\"https://jobs.lever.co/hotstar/?location=Bangalore%2FMumbai%2F%20Gurgaon&department=1.%20Engineering&team=Social\",\"https://jobs.lever.co/hotstar/?location=Bangalore%2FMumbai%2F%20Gurgaon&department=1.%20Engineering&team=User%20and%20Subscriptions%20Management\"]\n",
    "global hotstarOpeningsTotal\n",
    "global hotstarOpenings\n",
    "hotstarOpeningsTotal = 0\n",
    "hotstarOpenings = []\n",
    "nojo = 1\n",
    "print('Updating Disney + Hotstar Openings')\n",
    "for url in urls:\n",
    "    driver.get(url) \n",
    "    print(\"Working on page \"+str(urls.index(url)+1), end=' ')\n",
    "    for i in range(10):\n",
    "        print(\".\",end='')\n",
    "        time.sleep(1) \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    count = 0\n",
    "    job_profiles = soup.find_all('div', {'class' : 'posting'})\n",
    "    if len(job_profiles) > 0:\n",
    "        for job_profile in job_profiles :\n",
    "            b = job_profile.find('span', {'class' : 'sort-by-location'}).text\n",
    "            a = job_profile.find('a', {'class' : 'posting-title'}).text.split(b)[0]\n",
    "            if (not re.search(\"Senior\",a)) and (not re.search(\"Manager\",a)):\n",
    "                hotstarOpenings.append({\"Serial\":nojo,\"Title\":a,\"Location\":b,\"Link\":driver.find_element_by_xpath(\"//a[@class='posting-btn-submit template-btn-submit black']\").get_attribute(\"href\")})\n",
    "                nojo += 1\n",
    "            count = count + 1\n",
    "            print('.',end='')\n",
    "    print()\n",
    "    print(\"Page \"+str(urls.index(url)+1)+\" done\")\n",
    "hotstarOpeningsTotal += nojo\n",
    "totalOpenings += hotstarOpeningsTotal\n",
    "print()\n",
    "print(\"Disney + Hotstar Openings Updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Facebook - Software Development Engineer Job Search\n",
    "global fbOpeningsTotal\n",
    "global fbOpenings\n",
    "fbOpeningsTotal = 0\n",
    "fbOpenings = []\n",
    "url = \"https://www.facebook.com/careers/jobs?page=1&results_per_page=100&sub_teams[0]=Artificial%20Intelligence&sub_teams[1]=Computer%20Vision&sub_teams[2]=Data%20Science&sub_teams[3]=Engineering&sub_teams[4]=IT&sub_teams[5]=Machine%20Learning&sub_teams[6]=Solutions%20Engineering&sub_teams[7]=User%20Experience&offices[0]=Bangalore%2C%20India&offices[1]=Hyderabad%2C%20India&offices[2]=New%20Delhi%2C%20India&offices[3]=Mumbai%2C%20India&offices[4]=Gurgaon%2C%20India#search_result\"\n",
    "urll = 'https://www.facebook.com/careers/jobs?results_per_page=100&sub_teams[0]=Artificial%20Intelligence&sub_teams[1]=Computer%20Vision&sub_teams[2]=Data%20Science&sub_teams[3]=Engineering&sub_teams[4]=IT&sub_teams[5]=Machine%20Learning&sub_teams[6]=Solutions%20Engineering&sub_teams[7]=User%20Experience&sub_teams[8]=Client%20Solutions&offices[0]=Bangalore%2C%20India&offices[1]=Hyderabad%2C%20India&offices[2]=New%20Delhi%2C%20India&offices[3]=Mumbai%2C%20India&offices[4]=Gurgaon%2C%20India#search_result' \n",
    "driver.get(urll)\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "count = 0\n",
    "print(\"Working on it \", end='')\n",
    "job_profiles = soup.find_all('a', {'class' : '_8sef'})\n",
    "for job_profile in job_profiles :\n",
    "    a = job_profile.find_all('div', {'class' : '_8see'})[0].text\n",
    "    b = str(job_profile).split('href=\"')[1].split('\"')[0]\n",
    "    if(re.search(\"\\+\",a)):\n",
    "        a = a.split('+')[0] + ' + ' + driver.find_element_by_xpath(\"//a[@href='\"+b+\"']//div//div//div[@class='_8see']//div\").get_attribute(\"data-tooltip-content\")\n",
    "    fbOpenings.append({\"Serial\":count+1,\"Title\":job_profile.find('div', {'class' : '_8sel'}).text,\"Location\":a,\"Category\":job_profile.find_all('div', {'class' : '_8see'})[1].text,\"Link\":\"https://facebook.com\"+b})\n",
    "    count += 1\n",
    "    print('.',end='')\n",
    "print()\n",
    "print(\"Facebook Openings Updated\")\n",
    "fbOpeningsTotal = count\n",
    "totalOpenings += fbOpeningsTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter - Software Development Engineer Job Search\n",
    "global twitterOpeningsTotal\n",
    "global twitterOpenings\n",
    "twitterOpeningsTotal = 0\n",
    "twitterOpenings = []\n",
    "url = \"https://careers.twitter.com/content/careers-twitter/en/roles.html#location=careers-twitter%3Asr%2Foffice%2Fin%2Fbangalore&location=careers-twitter%3Asr%2Foffice%2Fin%2Fdelhi&location=careers-twitter%3Asr%2Foffice%2Fin%2Fmumbai&location=careers-twitter%3Asr%2Foffice%2Fin%2Fremote-india&q=software%20developer&sortBy=modified&team=careers-twitter%3Asr%2Fteam%2Fdata-science-and-analytics&team=careers-twitter%3Asr%2Fteam%2Fit-it-enterprise-applications&team=careers-twitter%3Asr%2Fteam%2Fmachine-learning&team=careers-twitter%3Asr%2Fteam%2Fsoftware-engineering\"\n",
    "driver.get(url)\n",
    "print('Updating Twitter Openings', end='')\n",
    "for i in range(10):\n",
    "    print(\".\",end='')\n",
    "    time.sleep(1) \n",
    "print()\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "totals = int(soup.find('span', {'class' : 'cr01__results-count chirp--bold-50'}).text.split(\"of \")[1].split(\" \")[0])\n",
    "nopa = totals//15\n",
    "if nopa > 0:\n",
    "    submit = driver.find_element_by_xpath(\"//button[@class='chirp-btn cr01__button-more  chirp-btn--black chirp-btn--primary']\")\n",
    "print(\"Working on it \", end='')\n",
    "count = 0\n",
    "while nopa > 0:\n",
    "    driver.execute_script(\"arguments[0].click();\", submit);\n",
    "    time.sleep(2)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    nopa -= 1\n",
    "    print('.',end='')\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "job_profiles = soup.find_all('a', {'class' : 'cr01__result-body'})\n",
    "nojo = 1\n",
    "for job_profile in job_profiles :\n",
    "    a = job_profile.find('h3', {'class' : 'cr01__result-title'}).text\n",
    "    if (not re.search(\"Senior\",a)) and (not re.search(\"Manager\",a)):\n",
    "        twitterOpenings.append({\"Serial\":nojo,\"Title\":a,\"Location\": job_profile.find_all('span', {'class' : 'cr01__result-subtitle'})[1].text,\"Link\":str(job_profile).split('href=\"')[1].split('\"')[0]})\n",
    "        nojo += 1\n",
    "    count += 1\n",
    "    print('.',end='')\n",
    "print()\n",
    "print(\"Twitter Openings Updated\")\n",
    "twitterOpeningsTotal = nojo\n",
    "totalOpenings += twitterOpeningsTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adobe - Software Development Engineer Job Search\n",
    "global adobeOpeningsTotal\n",
    "global adobeOpenings\n",
    "adobeOpeningsTotal = 0\n",
    "adobeOpenings = []\n",
    "url = \"https://adobe.wd5.myworkdayjobs.com/en-US/external_experienced\"\n",
    "driver.get(url) \n",
    "print('Updating Adobe Openings', end='')\n",
    "for i in range(10):\n",
    "    print(\".\",end='')\n",
    "    time.sleep(1) \n",
    "print()\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "ids = ['wd-FacetValue-CheckBox-locationCountry::c4f78be1a8f14da0ab49ce1162348a5e-input','wd-FacetValue-CheckBox-jobFamilyGroup::591af8b812fa10737af39db3d96eed9f-input','wd-FacetValue-CheckBox-jobFamilyGroup::591af8b812fa10737b0e880e0e3eeee9-input']\n",
    "for eid in ids:\n",
    "    submit = driver.find_element_by_id(eid)\n",
    "    driver.execute_script(\"arguments[0].click();\", submit);\n",
    "    time.sleep(3) \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "totals = int(soup.find('span', {'class' : 'gwt-InlineLabel WMNO WNNO'}).text.split(\" \")[0])\n",
    "nopa = totals//50\n",
    "while nopa > 0:\n",
    "    elementer = driver.find_element_by_xpath(\"//div[@class='WAOO WENO']\")\n",
    "    driver.execute_script(\"window.scrollTo(0, arguments[0].scrollHeight);\", elementer);\n",
    "    time.sleep(2)\n",
    "    driver.execute_script(\"window.scrollTo(0,0);\");\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    nopa -= 1\n",
    "count = 0\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "print(\"Working on it \", end='')\n",
    "jono = 1\n",
    "job_profiles = soup.find_all('li', {'class' : 'WP4F WBPO WAAB WGAG'})\n",
    "for job_profile in job_profiles :\n",
    "    a = job_profile.find('div', {'class' : 'gwt-Label WACP WJAP'}).text\n",
    "    if (not re.search(\"Senior\",a)) and (not re.search(\"Manager\",a)) and (not re.search(\"II\",a)) and (not re.search(\"2\",a)) and (not re.search(\"Lead\",a)):\n",
    "        adobeOpenings.append({\"Serial\":jono,\"Title\":a,\"Location\":job_profile.find('span', {'class' : 'gwt-InlineLabel WDAG WC5F'}).text.split(' | ')[1].split(',')[0],\"ID\":job_profile.find('span', {'class' : 'gwt-InlineLabel WDAG WC5F'}).text.split(' | ')[0],\"Posted\":job_profile.find('span', {'class' : 'gwt-InlineLabel WDAG WC5F'}).text.split(' | ')[2].split(\"Posted \")[1]})\n",
    "        jono += 1\n",
    "    count = count + 1\n",
    "    print('.',end='')\n",
    "print()\n",
    "print(\"Adobe Openings Updated\")\n",
    "adobeOpeningsTotal = jono\n",
    "totalOpenings += adobeOpeningsTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MasterCard - Software Development Engineer Job Search\n",
    "global masterOpeningsTotal\n",
    "global masterOpenings\n",
    "masterOpeningsTotal = 0\n",
    "masterOpenings = []\n",
    "url = \"https://mastercard.wd1.myworkdayjobs.com/CorporateCareers/\"\n",
    "driver.get(url) \n",
    "print('Updating MasterCard Openings', end='')\n",
    "for i in range(10):\n",
    "    print(\".\",end='')\n",
    "    time.sleep(1) \n",
    "print()\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "submit = driver.find_element_by_id('wd-FacetValue-CheckBox-locations::8eab563831bf10acbc722e4859721571-input')\n",
    "driver.execute_script(\"arguments[0].click();\", submit);\n",
    "time.sleep(3) \n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "ids = ['wd-FacetValue-CheckBox-jobFamilyGroup::866c0ed135ff106f00587685e7483440-input','wd-FacetValue-CheckBox-locations::8eab563831bf10acb97b7fba5feff76e-input','wd-FacetValue-CheckBox-jobFamilyGroup::62eb357456311007ffe9529562417cd4-input','wd-FacetValue-CheckBox-jobFamilyGroup::866c0ed135ff106f00a52e9d27783579-input','wd-FacetValue-CheckBox-jobFamilyGroup::866c0ed135ff106f00a52e9d27783579-input','wd-FacetValue-CheckBox-jobFamilyGroup::32c63b91509d1037cdc1ee728fc05b02-input','wd-FacetValue-CheckBox-jobFamilyGroup::70c27ec1148d483eb285aaadb278ef42-input','wd-FacetValue-CheckBox-jobFamilyGroup::79159e74ef6f01a1ba398ea19325020c-input','wd-FacetValue-CheckBox-jobFamilyGroup::2008c8ccf9ae4e56b7d0ea7b3d319a98-input']\n",
    "for eid in ids:\n",
    "    submit = driver.find_element_by_id(eid)\n",
    "    driver.execute_script(\"arguments[0].click();\", submit);\n",
    "    time.sleep(3) \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "totals = int(soup.find('span', {'class' : 'gwt-InlineLabel WMNO WNNO'}).text.split(\" \")[0])\n",
    "nopa = totals//50\n",
    "while nopa > 0:\n",
    "    elementer = driver.find_element_by_xpath(\"//div[@class='WAOO WENO']\")\n",
    "    driver.execute_script(\"window.scrollTo(0, arguments[0].scrollHeight);\", elementer);\n",
    "    time.sleep(2)\n",
    "    driver.execute_script(\"window.scrollTo(0,0);\");\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    nopa -= 1\n",
    "count = 0\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "print(\"Working on it \", end='')\n",
    "jono = 1\n",
    "job_profiles = soup.find_all('li', {'class' : 'WP4F WBPO WAAB WGAG'})\n",
    "for job_profile in job_profiles :\n",
    "    a = job_profile.find('div', {'class' : 'gwt-Label WACP WJAP'}).text\n",
    "    if (not re.search(\"Senior\",a)) and (not re.search(\"Manager\",a)) and (not re.search(\"II\",a)) and (not re.search(\"2\",a)) and (not re.search(\"Lead\",a)) and (not re.search(\"Director\",a)) and (not re.search(\"Prinipal\",a)) and (not re.search(\"President\",a)):\n",
    "        masterOpenings.append({\"Serial\":jono,\"Title\":a,\"Location\":job_profile.find('span', {'class' : 'gwt-InlineLabel WDAG WC5F'}).text.split(' | ')[1].split(',')[0],\"ID\":job_profile.find('span', {'class' : 'gwt-InlineLabel WDAG WC5F'}).text.split(' | ')[0],\"Posted\":job_profile.find('span', {'class' : 'gwt-InlineLabel WDAG WC5F'}).text.split(' | ')[2].split(\"Posted \")[1]})\n",
    "        jono += 1\n",
    "    count = count + 1\n",
    "    print('.',end='')\n",
    "print()\n",
    "print(\"MasterCard Openings Updated\")\n",
    "masterOpeningsTotal = jono\n",
    "totalOpenings += masterOpeningsTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ThomsonReuters - Software Development Engineer Job Search\n",
    "global reuterOpeningsTotal\n",
    "global reuterOpenings\n",
    "reuterOpeningsTotal = 0\n",
    "reuterOpenings = []\n",
    "url = \"https://thomsonreuters.wd5.myworkdayjobs.com/External_Career_Site/5/refreshFacet/318c8bb6f553100021d223d9780d30be\"\n",
    "driver.get(url) \n",
    "print('Updating ThomsonReuters Openings', end='')\n",
    "for i in range(10):\n",
    "    print(\".\",end='')\n",
    "    time.sleep(1) \n",
    "print()\n",
    "html = driver.page_source\n",
    "ids = ['wd-FacetValue-CheckBox-Location_Country::c4f78be1a8f14da0ab49ce1162348a5e-input','wd-FacetValue-CheckBox-jobFamilyGroup::45878602fca640ccb862953105224698-input','wd-FacetValue-CheckBox-jobFamilyGroup::1efb1a6360c4495c8288c5245f7f4461-input']\n",
    "for eid in ids:\n",
    "    submit = driver.find_element_by_id(eid)\n",
    "    driver.execute_script(\"arguments[0].click();\", submit);\n",
    "    time.sleep(3) \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "totals = int(soup.find('span', {'class' : 'gwt-InlineLabel WMNO WNNO'}).text.split(\" \")[0])\n",
    "nopa = totals//50\n",
    "while nopa > 0:\n",
    "    elementer = driver.find_element_by_xpath(\"//div[@class='WAOO WENO']\")\n",
    "    driver.execute_script(\"window.scrollTo(0, arguments[0].scrollHeight);\", elementer);\n",
    "    time.sleep(2)\n",
    "    driver.execute_script(\"window.scrollTo(0,0);\");\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    nopa -= 1\n",
    "count = 0\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "print(\"Working on it \", end='')\n",
    "jono = 1\n",
    "job_profiles = soup.find_all('li', {'class' : 'WP4F WBPO WAAB WGAG'})\n",
    "for job_profile in job_profiles :\n",
    "    a = job_profile.find('div', {'class' : 'gwt-Label WACP WJAP'}).text\n",
    "    if (not re.search(\"Senior\",a)) and (not re.search(\"Manager\",a)) and (not re.search(\"II\",a)) and (not re.search(\"2\",a)) and (not re.search(\"Lead\",a)):\n",
    "        reuterOpenings.append({\"Serial\":jono,\"Title\":a,\"Location\":job_profile.find('span', {'class' : 'gwt-InlineLabel WDAG WC5F'}).text.split(' | ')[1].split(',')[0],\"ID\":job_profile.find('span', {'class' : 'gwt-InlineLabel WDAG WC5F'}).text.split(' | ')[0],\"Posted\":job_profile.find('span', {'class' : 'gwt-InlineLabel WDAG WC5F'}).text.split(' | ')[2].split(\"Posted \")[1]})\n",
    "        jono += 1\n",
    "    count = count + 1\n",
    "    print('.',end='')\n",
    "print()\n",
    "print(\"ThomsonReuters Openings Updated\")\n",
    "reuterOpeningsTotal = jono\n",
    "totalOpenings += reuterOpeningsTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boeing - Software Development Engineer Job Search\n",
    "global boeingOpeningsTotal\n",
    "global boeingOpenings\n",
    "boeingOpeningsTotal = 0\n",
    "boeingOpenings = []\n",
    "url = \"https://boeing.wd1.myworkdayjobs.com/EXTERNAL_CAREERS/\"\n",
    "driver.get(url) \n",
    "print('Updating Boeing Openings', end='')\n",
    "for i in range(10):\n",
    "    print(\".\",end='')\n",
    "    time.sleep(1) \n",
    "print()\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "submit = driver.find_element_by_id('wd-FacetValue-CheckBox-locations::8b618a30e00f01736afdd74c1b3f5d89-input')\n",
    "driver.execute_script(\"arguments[0].click();\", submit);\n",
    "time.sleep(3) \n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "submit = driver.find_element_by_id('wd-FacetValue-CheckBox-jobFamilyGroup::8b618a30e00f01c7277572e8143f8b25-input')\n",
    "driver.execute_script(\"arguments[0].click();\", submit);\n",
    "time.sleep(3) \n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "totals = int(soup.find('span', {'class' : 'gwt-InlineLabel WMNO WNNO'}).text.split(\" \")[0])\n",
    "nopa = totals//50\n",
    "while nopa > 0:\n",
    "    elementer = driver.find_element_by_xpath(\"//div[@class='WAOO WENO']\")\n",
    "    driver.execute_script(\"window.scrollTo(0, arguments[0].scrollHeight);\", elementer);\n",
    "    time.sleep(2)\n",
    "    driver.execute_script(\"window.scrollTo(0,0);\");\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    nopa -= 1\n",
    "count = 0\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "print(\"Working on it \", end='')\n",
    "jono = 1\n",
    "job_profiles = soup.find_all('li', {'class' : 'WP4F WBPO WAAB WGAG'})\n",
    "for job_profile in job_profiles :\n",
    "    a = job_profile.find('div', {'class' : 'gwt-Label WACP WJAP'}).text\n",
    "    if (not re.search(\"Senior\",a)) and (not re.search(\"Manager\",a)) and (not re.search(\"II\",a)) and (not re.search(\"2\",a)) and (not re.search(\"Lead\",a)):\n",
    "        boeingOpenings.append({\"Serial\":jono,\"Title\":a,\"ID\":job_profile.find('span', {'class' : 'gwt-InlineLabel WDAG WC5F'}).text.split(' | ')[1].split(',')[0],\"Location\":job_profile.find('span', {'class' : 'gwt-InlineLabel WDAG WC5F'}).text.split(' | ')[0].split('- ')[1].split(',')[0],\"Posted\":job_profile.find('span', {'class' : 'gwt-InlineLabel WDAG WC5F'}).text.split(' | ')[2].split(\"Posted \")[1]})\n",
    "        jono += 1\n",
    "    count = count + 1\n",
    "    print('.',end='')\n",
    "print()\n",
    "print(\"Boeing Openings Updated\")\n",
    "boeingOpeningsTotal = jono\n",
    "totalOpenings += boeingOpeningsTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finastra - Software Development Engineer Job Search\n",
    "global finastraOpeningsTotal\n",
    "global finastraOpenings\n",
    "finastraOpeningsTotal = 0\n",
    "finastraOpenings = []\n",
    "url = \"https://dh.wd3.myworkdayjobs.com/DHC/jobs\"\n",
    "driver.get(url) \n",
    "print('Updating Finastra Openings', end='')\n",
    "for i in range(10):\n",
    "    print(\".\",end='')\n",
    "    time.sleep(1) \n",
    "print()\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "ids = ['wd-FacetValue-CheckBox-jobFamilyGroup::074628e3389f10fa1c9fcbe9095e2186-input','wd-FacetValue-CheckBox-jobFamilyGroup::074628e3389f10fa1c9f02dbb77b2162-input','wd-FacetValue-CheckBox-locations::8061b46e841701674a93fa087a40597d-input','wd-FacetValue-CheckBox-locations::9ab6e37cf0b510c4241704726a7e106e-input','wd-FacetValue-CheckBox-locations::9883965210a71070ff94dc364880e8fa-input']\n",
    "for eid in ids:\n",
    "    submit = driver.find_element_by_id(eid)\n",
    "    driver.execute_script(\"arguments[0].click();\", submit);\n",
    "    time.sleep(3) \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "totals = int(soup.find('span', {'class' : 'gwt-InlineLabel WMNO WNNO'}).text.split(\" \")[0])\n",
    "nopa = totals//50\n",
    "while nopa > 0:\n",
    "    elementer = driver.find_element_by_xpath(\"//div[@class='WAOO WENO']\")\n",
    "    driver.execute_script(\"window.scrollTo(0, arguments[0].scrollHeight);\", elementer);\n",
    "    time.sleep(2)\n",
    "    driver.execute_script(\"window.scrollTo(0,0);\");\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    nopa -= 1\n",
    "count = 0\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "print(\"Working on it \", end='')\n",
    "jono = 1\n",
    "job_profiles = soup.find_all('li', {'class' : 'WP4F WBPO WAAB WGAG'})\n",
    "for job_profile in job_profiles :\n",
    "    a = job_profile.find('div', {'class' : 'gwt-Label WACP WJAP'}).text\n",
    "    if (not re.search(\"Senior\",a)) and (not re.search(\"Manager\",a)) and (not re.search(\"II\",a)) and (not re.search(\"2\",a)) and (not re.search(\"Lead\",a)):\n",
    "        finastraOpenings.append({\"Serial\":jono,\"Title\":a,\"Location\":job_profile.find('span', {'class' : 'gwt-InlineLabel WDAG WC5F'}).text.split(' | ')[1].split(',')[0],\"ID\":job_profile.find('span', {'class' : 'gwt-InlineLabel WDAG WC5F'}).text.split(' | ')[0],\"Posted\":job_profile.find('span', {'class' : 'gwt-InlineLabel WDAG WC5F'}).text.split(' | ')[2].split(\"Posted \")[1]})\n",
    "        jono += 1\n",
    "    count = count + 1\n",
    "    print('.',end='')\n",
    "print()\n",
    "print(\"Finastra Openings Updated\")\n",
    "finastraOpeningsTotal = jono\n",
    "totalOpenings += finastraOpeningsTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PayPal - Software Development Engineer Job Search\n",
    "global paypalOpeningsTotal\n",
    "global paypalOpenings\n",
    "paypalOpeningsTotal = 0\n",
    "paypalOpenings = []\n",
    "url = \"https://wd1.myworkdaysite.com/recruiting/paypal/jobs\"\n",
    "driver.get(url) \n",
    "print('Updating PayPal Openings', end='')\n",
    "for i in range(10):\n",
    "    print(\".\",end='')\n",
    "    time.sleep(1) \n",
    "print()\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "ids = ['wd-FacetValue-CheckBox-jobFamilyGroup::faedd7c80dd5102a1e369f8dcda9ca60-input','wd-FacetValue-CheckBox-jobFamilyGroup::faedd7c80dd5102a1e3685d24992ca28-input','wd-FacetValue-CheckBox-jobFamilies::faedd7c80dd5102a1d99b3904b1de931-input','wd-FacetValue-CheckBox-jobFamilies::faedd7c80dd5102a1d99f311e73ae967-input','wd-FacetValue-CheckBox-jobFamilies::14928883eae20143118338bc6501c004-input','wd-FacetValue-CheckBox-jobFamilies::18f4ea36abe801dc71e5e3846501ed03-input','wd-FacetValue-CheckBox-jobFamilies::faedd7c80dd5102a1d99bd84478de939-input','wd-FacetValue-CheckBox-jobFamilies::8ca194056bf1016bf003108a65014a02-input','wd-FacetValue-CheckBox-locations::bcdc9518960a0115db738aaa2d241899-input','wd-FacetValue-CheckBox-locations::bcdc9518960a01a46ac477aa2d240c99-input','wd-FacetValue-CheckBox-locations::bcdc9518960a01d7641b93ac2d246c9a-input','wd-FacetValue-CheckBox-locations::bcdc9518960a0124bac97daa2d241099-input']\n",
    "for eid in ids:\n",
    "    submit = driver.find_element_by_id(eid)\n",
    "    driver.execute_script(\"arguments[0].click();\", submit);\n",
    "    time.sleep(3) \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "totals = int(soup.find('span', {'class' : 'gwt-InlineLabel WMNO WNNO'}).text.split(\" \")[0])\n",
    "nopa = totals//50\n",
    "while nopa > 0:\n",
    "    elementer = driver.find_element_by_xpath(\"//div[@class='WAOO WENO']\")\n",
    "    driver.execute_script(\"window.scrollTo(0, arguments[0].scrollHeight);\", elementer);\n",
    "    time.sleep(2)\n",
    "    driver.execute_script(\"window.scrollTo(0,0);\");\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    nopa -= 1\n",
    "count = 0\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "print(\"Working on it \", end='')\n",
    "jono = 1\n",
    "job_profiles = soup.find_all('li', {'class' : 'WP4F WBPO WAAB WGAG'})\n",
    "for job_profile in job_profiles :\n",
    "    a = job_profile.find('div', {'class' : 'gwt-Label WACP WJAP'}).text\n",
    "    if (not re.search(\"Senior\",a)) and (not re.search(\"Manager\",a)) and (not re.search(\"II\",a)) and (not re.search(\"2\",a)) and (not re.search(\"Lead\",a)) and (not re.search(\"3\",a)):\n",
    "        paypalOpenings.append({\"Serial\":jono,\"Title\":a,\"Location\":job_profile.find('span', {'class' : 'gwt-InlineLabel WDAG WC5F'}).text.split(' | ')[1].split(',')[0],\"ID\":job_profile.find('span', {'class' : 'gwt-InlineLabel WDAG WC5F'}).text.split(' | ')[0],\"Posted\":job_profile.find('span', {'class' : 'gwt-InlineLabel WDAG WC5F'}).text.split(' | ')[2].split(\"Posted \")[1]})\n",
    "        jono += 1\n",
    "    count = count + 1\n",
    "    print('.',end='')\n",
    "driver.close()\n",
    "print()\n",
    "print(\"PayPal Openings Updated\")\n",
    "paypalOpeningsTotal = jono\n",
    "totalOpenings += paypalOpeningsTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\\# Honeywell - Software Development Engineer Job Search\n",
    "global honeyOpeningsTotal\n",
    "global honeyOpenings\n",
    "honeyOpeningsTotal = 0\n",
    "honeyOpenings = []\n",
    "url = \"https://careers.honeywell.com/us/en/search-results?keywords=\"\n",
    "driver = webdriver.Chrome('chromedriver')  \n",
    "driver.minimize_window()\n",
    "driver.get(url) \n",
    "print('Updating Honeywell Openings', end='')\n",
    "for i in range(10):\n",
    "    print(\".\",end='')\n",
    "    time.sleep(1) \n",
    "print()\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "ids = ['Country /Region-19','Category-3','Category-6','Category-10']\n",
    "for eid in ids:\n",
    "    submit = driver.find_element_by_id(eid)\n",
    "    driver.execute_script(\"arguments[0].click();\", submit);\n",
    "    time.sleep(3) \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "totals = int(soup.find('span', {'class' : 'result-count'}).text)\n",
    "nopa = totals//10\n",
    "job_profiles = soup.find_all('div', {'class' : 'information'})\n",
    "count = 0\n",
    "jono = 1\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "print(\"Working on it \", end='')\n",
    "while nopa > -1:\n",
    "    for job_profile in job_profiles :\n",
    "        a = job_profile.find('div',{'class':'job-title'}).text.strip()\n",
    "        if (not re.search(\"Senior\",a)) and (not re.search(\"Manager\",a)) and (not re.search(\"III\",a)) and (not re.search(\"3\",a)) and (not re.search(\"Lead\",a)) and (not re.search(\"Sr\",a)):\n",
    "            honeyOpenings.append({\"Serial\":jono,\"Title\":a,\"Department\":job_profile.find('span', {'class' : 'job-category'}).text.split(\"Category\")[1].strip()})\n",
    "            jono += 1\n",
    "        count = count + 1\n",
    "        print('.',end='')\n",
    "    if nopa > 0:\n",
    "        submit = driver.find_element_by_xpath(\"//span[@class='icon icon-arrow-right']\")\n",
    "        driver.execute_script(\"arguments[0].click();\", submit);\n",
    "    nopa -= 1\n",
    "    time.sleep(10)\n",
    "    print(\"%i pages left\"%(nopa+1))\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "driver.close() \n",
    "print()\n",
    "print(\"Honeywell Openings Updated\")\n",
    "honeyOpeningsTotal = jono\n",
    "totalOpenings += honeyOpeningsTotal\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global jobtime\n",
    "jobtime = (time.time() - jstime)//60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jobtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Oracle - Software Development Engineer Job Search\n",
    "global oracleOpeningsTotal\n",
    "global oracleOpenings\n",
    "oracleOpeningsTotal = 0\n",
    "oracleOpenings = []\n",
    "url = \"https://eeho.fa.us2.oraclecloud.com/hcmUI/CandidateExperience/en/sites/CX_1/requisitions?lastSelectedFacet=POSTING_DATES&location=India&locationId=300000000106947&locationLevel=country&selectedCategoriesFacet=300000001917356;300000001917346&selectedPostingDatesFacet=30&sortBy=POSTING_DATES_DESC\"\n",
    "driver.get(url)\n",
    "print('Updating Oracle Openings', end='')\n",
    "for i in range(15):\n",
    "    print(\".\",end='')\n",
    "    time.sleep(1) \n",
    "print()\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "totals = int(soup.find('span', {'class' : 'search-results-title-job-count'}).text.split(\" \")[0])\n",
    "nopa = totals//25\n",
    "if nopa > 0:\n",
    "    elementer = driver.find_element_by_xpath(\"//ul[@class='joblist-grid']\")\n",
    "    driver.execute_script(\"window.scrollTo(0, arguments[0].scrollHeight);\", elementer);\n",
    "    time.sleep(2)\n",
    "    driver.execute_script(\"window.scrollTo(0,0);\");\n",
    "    time.sleep(2)\n",
    "    driver.execute_script(\"window.scrollTo(0, arguments[0].scrollHeight);\", elementer);\n",
    "    time.sleep(5)\n",
    "    nopa -=1\n",
    "time.sleep(10)\n",
    "while nopa > 1:\n",
    "    submit = driver.find_element_by_xpath(\"//button[@class='search-results-load-more-btn']\")\n",
    "    driver.execute_script(\"arguments[0].click();\", submit);\n",
    "    time.sleep(10)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    print(\"%i pages left\"%(nopa-1))\n",
    "    nopa -= 1\n",
    "count = 0\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "print(\"Working on it \", end='')\n",
    "jono = 1\n",
    "job_profiles = soup.find_all('search-result-item', {'class' : 'search-result-item'})\n",
    "for job_profile in job_profiles :\n",
    "    a = job_profile.find('h3', {'class' : 'job-title'}).text\n",
    "    if (not re.search(\"Senior\",a)) and (not re.search(\"Manager\",a)) and (not re.search(\"II\",a)) and (not re.search(\"2\",a)) and (not re.search(\"Lead\",a)) and (not re.search(\"Director\",a)) and (not re.search(\"Principal\",a)) and (not re.search(\"President\",a)) and (not re.search(\"3\",a)) and (not re.search(\"4\",a)) and (not re.search(\"5\",a)) and (not re.search(\"6\",a)):\n",
    "        oracleOpenings.append({\"Serial\":jono,\"Title\":a,\"Location\":job_profile.find('span', {'class' : 'job-location'}).text.split(',')[0],\"Description\":re.sub('\\\\n', '', job_profile.find('div', {'class' : 'job-description'}).text)})\n",
    "        jono += 1\n",
    "    count = count + 1\n",
    "    print('.',end='')\n",
    "driver.close()\n",
    "print()\n",
    "print(\"Oracle Openings Updated\")\n",
    "oracleOpeningsTotal = jono\n",
    "totalOpenings += oracleOpeningsTotal\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global tottime\n",
    "tottime = (time.time() - starttime)//60\n",
    "print(apptime)\n",
    "print(jobtime)\n",
    "print(tottime)\n",
    "newContent = \"\\n\" + \"var totjob = \"+ str(totalOpenings) + \";\" + \"\\n\"  + \"var amazonapp = \"+ str(amazonOpenings) + \"\\n\" + \"var linkedinapp = \"+ str(hotstarOpenings) + \"\\n\" + \"var dellapp = \"+ str(dellOpenings) + \"\\n\" + \"var adobeapp = \"+ str(adobeOpenings) + \"\\n\" + \"var masterapp = \"+ str(masterOpenings) + \"\\n\" + \"var reuterapp = \"+ str(reuterOpenings) + \"\\n\" + \"var boeingapp = \"+ str(boeingOpenings) + \"\\n\" + \"var paypalapp = \"+ str(paypalOpenings) + \"\\n\" + \"var finastraapp = \"+ str(finastraOpenings) + \"\\n\" + \"var honeyapp = \"+ str(fbOpenings) + \"\\n\" + \"var naukritapp = \"+ str(twitterOpenings) + \"\\n\"  + \"var amazoncon = \"+ str(amazonOpeningsTotal) + \"\\n\" + \"var linkedincon = \"+ str(hotstarOpeningsTotal) + \"\\n\" + \"var dellcon = \"+ str(dellOpeningsTotal) + \"\\n\" + \"var adobecon = \"+ str(adobeOpeningsTotal) + \"\\n\" + \"var mastercon = \"+ str(masterOpeningsTotal) + \"\\n\" + \"var reutercon = \"+ str(reuterOpeningsTotal) + \"\\n\" + \"var boeingcon = \"+ str(boeingOpeningsTotal) + \"\\n\" + \"var paypalcon = \"+ str(paypalOpeningsTotal) + \"\\n\" + \"var finastracon = \"+ str(finastraOpeningsTotal) + \"\\n\" + \"var honeycon = \"+ str(fbOpeningsTotal) + \"\\n\" + \"var naukritcon = \"+ str(twitterOpeningsTotal) + \"\\n\"\n",
    "\n",
    "with open(\"display/jse.html\", encoding=\"utf-8\") as inf:\n",
    "    txt = inf.read()\n",
    "    soup = BeautifulSoup(txt, \"html.parser\")\n",
    "\n",
    "a = soup.find(\"script\", {\"class\":\"contentInput\"})\n",
    "a.clear()\n",
    "a.append(newContent)\n",
    "with open(\"display/jse.html\", \"w\", encoding=\"utf-8\") as outf:\n",
    "    outf.write(str(soup))\n",
    "url = \"/display/jse.html\"\n",
    "driver = webdriver.Chrome('chromedriver')  \n",
    "driver.get(url)\n",
    "driver.maximize_window() "
   ]
  }
 ]
}